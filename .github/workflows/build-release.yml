name: build release
on:
  push:
    branches:
      - release
  pull_request:
    branches:
      - release
env:
  CUDA_VERSION: "12.1.0"
  CUDA_SUB_PACKAGES: '["cublas", "cublas_dev", "cudart", "curand", "curand_dev", "nvcc", "nvrtc", "nvrtc_dev", "thrust", "visual_studio_integration"]'
jobs:
  build:
    runs-on: windows-2022
    defaults:
      run:
        shell: bash -el {0}
    strategy:
      matrix:
        # https://en.wikipedia.org/wiki/CUDA#GPUs_supported
        artifact: [
          # {
          #   arch: "75",
          #   name: "Turing",
          #   gpus: "RTX 2060 - 2080 & Ti, Quadro RTX 4000 - 8000"
          # },
          {
            arch: "86",
            name: "Ampere",
            gpus: "RTX 3050 - 3090 & Ti, RTX A2000 - A6000"
          },
          # {
          #   arch: "89",
          #   name: "Lovelace",
          #   gpus: "RTX 4070 - 4090, RTX 6000 Ada"
          # }
        ]
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v3
        with:
          ref: ${{ github.sha }}
          submodules: recursive
      
      - name: Install CMake
        uses: lukka/get-cmake@v3.24.2

      - name: Cache Env File
        uses: actions/cache@v3
        id: cache-env-vars
        with:
          path: ~/cache-hash.env
          key: ${{ runner.os }}-env-vars-${{ hashFiles('~/cache-hash.env') }}
      
      - name: Restore Cached Env
        if: steps.cache-env-vars.outputs.cache-hit == 'true'
        run: |
          cat ~/cache-hash.env >> $GITHUB_ENV
      
      - name: test dummy cache write
        if: steps.cache-env-vars.outputs.cache-hit != 'true'
        run: |
          echo "CUDA_VERSION=aoeu" >> ~/cache-hash.env
          echo "CUDA_SUB_PACKAGES=ee11" >> ~/cache-hash.env
          echo "CUDA_PATH=fuubar" >> ~/cache-hash.env
        
      - name: test dummy cache read
        run: |
          echo ${{ env.CUDA_VERSION }}
          echo ${{ env.CUDA_SUB_PACKAGES }}
          echo $CUDA_PATH

      # - name: Cache CUDA Toolkit
      #   uses: actions/cache@v3
      #   id: cache-cuda-toolkit
      #   path: 

      # - name: Install CUDA Toolkit
      #   uses: JamesPerlman/get-cuda-toolkit@master
      #   if: steps.cache-cuda-toolkit.outputs.cache-hit != 'true'
      #   id: cuda-toolkit
      #   with:
      #     cuda: 
      #     method: 'network'
      #     # https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/
      #     sub-packages: '[
      #       "cublas",
      #       "cublas_dev",
      #       "cudart",
      #       "curand",
      #       "curand_dev",
      #       "nvcc",
      #       "nvrtc",
      #       "nvrtc_dev",
      #       "thrust",
      #       "visual_studio_integration"
      #     ]'
      #     run: |
      #       echo CUDA_VERSION=${{ steps.cuda-toolkit.outputs.cuda-version }} >> ~/cache-hash.env
      #       echo CUDA_SUB_PACKAGES=${{ steps.cuda-toolkit.outputs.sub-packages }} >> ~/cache-hash.env
      #       echo CUDA_PATH=${{ steps.cuda-toolkit.outputs.cuda-path }} >> ~/cache-hash.env
            


      # - name: List installed subpackages
      #   run: |
      #     echo ${{ steps.cuda-toolkit.outputs.sub-packages }}
        
      # - name: List DLLs
      #   run: |
      #     ls "C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.1/bin"

      # - name: Setup Conda
      #   uses: conda-incubator/setup-miniconda@v2.2.0
      #   with:
      #     activate-environment: py310
      #     environment-file: etc/py310.yml
      #     auto-activate-base: false
      
      # - name: CMake Configure
      #   env:
      #     CUDA_ARCH_LIST: ${{ matrix.artifact.arch }}
      #     TCNN_CUDA_ARCHITECTURES: ${{ matrix.artifact.arch }}
          
      #   run: |
      #     cmake . \
      #       -B build \
      #       -G "Visual Studio 17 2022" \
      #       -A x64 \
      #       -DCMAKE_BUILD_TYPE=Release \
      #       -DPYTHON_EXECUTABLE="${CONDA_PREFIX}\\python.exe" \
      #       -DTN_BUILD_PYD=ON \
      #       -DTN_BUILD_EXE=OFF

      # - name: CMake Build
      #   run: cmake --build build --config Release -j
      
      # - name: Archive Build Result
      #   uses: thedoctor0/zip-release@0.7.1
      #   with:
      #     type: 'zip'
      #     path: build/Release/
      #     filename: 'TurboNeRF-${{ matrix.artifact.name }}.zip'

      # - name: Upload Binaries
      #   uses: ncipollo/release-action@v1
      #   with:
      #     allowUpdates: true
      #     body: 'Binary for NVIDIA ${{ matrix.artifact.name }} GPUs: ${{ matrix.artifact.gpus }}'
      #     bodyFile: 'TurboNeRF-${{ matrix.artifact.name }}.zip'
      #     commit: ${{ github.sha }}
      #     makeLatest: true
      #     name: 'TurboNeRF Pre-Release (${{ matrix.artifact.name }})'
      #     prerelease: true
      #     token: ${{ secrets.GITHUB_TOKEN }}
